{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    " <a href=\"http://cocl.us/pytorch_link_top\"><img src = \"http://cocl.us/Pytorch_top\" width = 950, align = \"center\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width = 200, align = \"center\">\n",
    "\n",
    "\n",
    "<h1 align=center><font size = 5>Test Uniform, Default and He Initialization on  MNIST Dataset  with Relu Activation</font></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Table of Contents\n",
    "In this lab, you will test Sigmoid, Tanh and Relu activations functions on the MNIST dataset \n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<li><a href=\"#ref1\">Neural Network Module and Training Function   </a></li>\n",
    "<li><a href=\"#ref2\"> Prepare Data </a></li>\n",
    "<li><a href=\"#ref3\">Define Several Neural Network, Criterion function, Optimizer</a></li>\n",
    "<li><a href=\"#ref4\">Test Uniform, Default and He Initialization </a></li>\n",
    "<li><a href=\"#ref4\">Analyse Results</a></li>\n",
    "<br>\n",
    "<p></p>\n",
    "Estimated Time Needed: <strong>25 min</strong>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll need the following libraries:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x9520c51730>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h2 align=center>Neural Network Module and Training Function </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the neural network module or class He Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_He(nn.Module):\n",
    "    def __init__(self,Layers):\n",
    "        super(Net_He,self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size,output_size in zip(Layers,Layers[1:]):\n",
    "            linear=nn.Linear(input_size,output_size)\n",
    "            torch.nn.init.kaiming_uniform_(linear.weight,nonlinearity='relu')\n",
    "            self.hidden.append(nn.Linear(input_size,output_size))\n",
    "\n",
    "    def forward(self,x):\n",
    "        L=len(self.hidden)\n",
    "        for (l,linear_transform)  in zip(range(L),self.hidden):\n",
    "            if l<L-1:\n",
    "                x =F.relu(linear_transform (x))\n",
    "           \n",
    "            else:\n",
    "                x =linear_transform (x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class or Neral Network with Uniform Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_Uniform(nn.Module):\n",
    "    def __init__(self,Layers):\n",
    "        super(Net_Uniform,self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size,output_size in zip(Layers,Layers[1:]):\n",
    "            linear=nn.Linear(input_size,output_size)\n",
    "            linear.weight.data.uniform_(0, 1)\n",
    "            #inear.weight.data.\n",
    "            self.hidden.append(linear)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        L=len(self.hidden)\n",
    "        for (l,linear_transform)  in zip(range(L),self.hidden):\n",
    "            if l<L-1:\n",
    "                x =F.relu(linear_transform (x))\n",
    "           \n",
    "            else:\n",
    "                x =linear_transform (x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class or Neral Network with Pytroch Default Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,Layers):\n",
    "        super(Net,self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "\n",
    "        for input_size,output_size in zip(Layers,Layers[1:]):\n",
    "            linear=nn.Linear(input_size,output_size)\n",
    "            \n",
    "            #inear.weight.data.\n",
    "            self.hidden.append(linear)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        L=len(self.hidden)\n",
    "        for (l,linear_transform)  in zip(range(L),self.hidden):\n",
    "            if l<L-1:\n",
    "                x =F.relu(linear_transform (x))\n",
    "           \n",
    "            else:\n",
    "                x =linear_transform (x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a function to  train the model, in this case the function returns a Python dictionary to store the training loss and accuracy on the validation data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,criterion, train_loader,validation_loader, optimizer, epochs=100):\n",
    "    i=0\n",
    "    useful_stuff={'training_loss':[],'validation_accuracy':[]}  \n",
    "    \n",
    "    #n_epochs\n",
    "    for epoch in range(epochs):\n",
    "        for i,(x, y) in enumerate(train_loader):\n",
    "\n",
    "            #clear gradient \n",
    "            optimizer.zero_grad()\n",
    "            #make a prediction logits \n",
    "            z=model(x.view(-1,28*28))\n",
    "            # calculate loss \n",
    "            loss=criterion(z,y)\n",
    "    \n",
    "            # calculate gradients of parameters \n",
    "            loss.backward()\n",
    "            # update parameters \n",
    "            optimizer.step()\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "        correct=0\n",
    "        for x, y in validation_loader:\n",
    "            #perform a prediction on the validation  data  \n",
    "            yhat=model(x.view(-1,28*28))\n",
    "            \n",
    "            _,lable=torch.max(yhat,1)\n",
    "            correct+=(lable==y).sum().item()\n",
    " \n",
    "    \n",
    "        accuracy=100*(correct/len(validation_dataset))\n",
    "   \n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    \n",
    "    return useful_stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h2 align=center>Prepare Data </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training dataset by setting the parameters <code>train </code> to <code>True</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=dsets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the testing dataset by setting the parameters train  <code>False</code> and convert it to a tensor  by placing a transform object int the argument <code>transform</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset=dsets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the criterion function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the training-data loader and the validation-data loader object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=2000,shuffle=True)\n",
    "validation_loader=torch.utils.data.DataLoader(dataset=validation_dataset,batch_size=5000,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref3\"></a>\n",
    "<h2 align=center>Define Neural Network, Criterion function, Optimizer and Train the  Model  </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create the criterion function  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a list that contains layer  size "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim=28*28\n",
    "\n",
    "output_dim=10\n",
    "\n",
    "layers=[input_dim,100,200,100,output_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print the model parameters "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref4\"></a>\n",
    "<h2 align=center>Test Pytroch Default Initialization,Xavier Initialization,Uniform Initialization  </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the network using Pytroch Default Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Net(layers)\n",
    "\n",
    "learning_rate=0.01\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "training_results=train(model,criterion, train_loader,validation_loader, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the network using He Initialization function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_He=Net_He(layers)\n",
    "optimizer=torch.optim.SGD(model_He.parameters(),lr=learning_rate)\n",
    "training_results_He=train(model_He,criterion, train_loader,validation_loader, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the network using the Relu activations function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Uniform=Net_Uniform(layers)\n",
    "optimizer=torch.optim.SGD(model_Uniform.parameters(),lr=learning_rate)\n",
    "training_results_Uniform=train(model_Uniform,criterion, train_loader,validation_loader, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref5\"></a>\n",
    "<h2 align=center>Analyse Results </h2> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the training loss for each activation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_results_He['training_loss'],label='He')\n",
    "plt.plot(training_results['training_loss'],label='default ')\n",
    "plt.plot(training_results_Uniform['training_loss'],label='Uniform')\n",
    "plt.ylabel('loss')\n",
    "plt.title('training loss iterations')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare the validation loss for each model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_results_He['validation_accuracy'],label='He')\n",
    "plt.plot(training_results['validation_accuracy'],label='default ')\n",
    "plt.plot(training_results_Uniform['validation_accuracy'],label='Uniform') \n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epochs ')   \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Authors:  \n",
    "[Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering. His research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. \n",
    "\n",
    "Other contributors: [Michelle Carey](  https://www.linkedin.com/in/michelleccarey/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  <hr>\n",
    "Copyright &copy; 2018 [cognitiveclass.ai](cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
