{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    " <a href=\"http://cocl.us/pytorch_link_top\"><img src = \"http://cocl.us/Pytorch_top\" width = 950, align = \"center\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://ibm.box.com/shared/static/ugcqz6ohbvff804xp84y4kqnvvk3bq1g.png\" width = 200, align = \"center\">\n",
    "\n",
    "<h1 align=center><font size = 5>Logistic Regression and Bad Initialization Value</font></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "In this lab, you will see what happens when you use the root mean square error cost or total loss function and select the bad initialization value for the parameter values.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<li><a href=\"#ref0\">Make Some Data</a></li>\n",
    "<li><a href=\"#ref1\">Create the Model and Cost Function the Pytorch way</a></li>\n",
    "<li><a href=\"#ref2\">Train the Model:Batch Gradient Descent</a></li>\n",
    "\n",
    "<br>\n",
    "<p></p>\n",
    "Estimated Time Needed: <strong>30 min</strong>\n",
    "</div>\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class <code>plot_error_surfaces</code> is just to help you visualize the data space and the parameter space during training and has nothing to do with Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class plot_error_surfaces(object):\n",
    "    def __init__(self,w_range, b_range,X,Y,n_samples=30,go=True):\n",
    "        W = np.linspace(-w_range, w_range, n_samples)\n",
    "        B = np.linspace(-b_range, b_range, n_samples)\n",
    "        w, b = np.meshgrid(W, B)    \n",
    "        Z=np.zeros((30,30))\n",
    "        count1=0\n",
    "        self.y=Y.numpy()\n",
    "        self.x=X.numpy()\n",
    "        for w1,b1 in zip(w,b):\n",
    "            count2=0\n",
    "            for w2,b2 in zip(w1,b1):\n",
    "                1 / (1 + np.exp(w2*self.x+b2))\n",
    "                Z[count1,count2]=np.mean((self.y-(1 / (1 + np.exp(w2*self.x+b2))))**2)\n",
    "                count2 +=1\n",
    "    \n",
    "            count1 +=1\n",
    "        self.Z=Z\n",
    "        self.w=w\n",
    "        self.b=b\n",
    "        self.W=[]\n",
    "        self.B=[]\n",
    "        self.LOSS=[]\n",
    "        self.n=0\n",
    "        if go==True:\n",
    "            plt.figure()\n",
    "            plt.figure(figsize=(7.5,5))\n",
    "            plt.axes(projection='3d').plot_surface(self.w, self.b, self.Z, rstride=1, cstride=1,cmap='viridis', edgecolor='none')\n",
    "            plt.title('Loss Surface')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.show()\n",
    "            plt.figure()\n",
    "            plt.title('Loss Surface Contour')\n",
    "            plt.xlabel('w')\n",
    "            plt.ylabel('b')\n",
    "            plt.contour(self.w, self.b, self.Z)\n",
    "            plt.show()\n",
    "    def get_stuff(self,model,loss):\n",
    "        self.n=self.n+1\n",
    "        self.W.append(list(model.parameters())[0].item())\n",
    "        self.B.append(list(model.parameters())[1].item())\n",
    "        self.LOSS.append(loss)\n",
    "        \n",
    "    def final_plot(self): \n",
    "        ax = plt.axes(projection='3d')\n",
    "        ax.plot_wireframe(self.w, self.b, self.Z)\n",
    "        ax.scatter(self.W,self.B, self.LOSS, c='r', marker='x',s=200,alpha=1)\n",
    "        plt.figure()\n",
    "        plt.contour(self.w,self.b, self.Z)\n",
    "        plt.scatter(self.W,self.B,c='r', marker='x')\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.show()\n",
    "    def plot_ps(self):\n",
    "        plt.subplot(121)\n",
    "        plt.ylim\n",
    "        plt.plot(self.x,self.y,'ro',label=\"training points\")\n",
    "        plt.plot(self.x,self.W[-1]*self.x+self.B[-1],label=\"estimated line\")\n",
    "        plt.plot(self.x,1 / (1 + np.exp(-1*(self.W[-1]*self.x+self.B[-1]))),label='sigmoid')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        plt.ylim((-0.1, 2))\n",
    "        plt.title('Data Space Iteration: '+str(self.n))\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        plt.subplot(122)\n",
    "        plt.contour(self.w,self.b, self.Z)\n",
    "        plt.scatter(self.W,self.B,c='r', marker='x')\n",
    "        plt.title('Loss Surface Contour Iteration'+str(self.n) )\n",
    "        plt.xlabel('w')\n",
    "        plt.ylabel('b')\n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotStuff(X,Y,model,epoch,leg=True):\n",
    "    plt.plot(X.numpy(),model(X).detach().numpy(),label='epoch '+str(epoch))\n",
    "    plt.plot(X.numpy(),Y.numpy(),'r')\n",
    "    if leg==True:\n",
    "        plt.legend()\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref0\"></a>\n",
    "<h2 align=center>Get Some Data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.arange(-1,1,0.1).view(-1,1)\n",
    "        self.y=-torch.zeros(self.x.shape[0],1)\n",
    "        self.y[self.x[:,0]>0.2]=1\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index],self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set=Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader=DataLoader(dataset=data_set,batch_size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref1\"></a>\n",
    "<h2 align=center>Create the Model and Total Loss Function (cost) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a custom module for logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_regression(nn.Module):\n",
    "    def __init__(self,n_inputs):\n",
    "        super(logistic_regression,self).__init__()\n",
    "        self.linear=nn.Linear(n_inputs,1)\n",
    "    def forward(self,x):\n",
    "        yhat=torch.sigmoid(self.linear(x))\n",
    "        return yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a logistic regression object or model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=logistic_regression(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the random initialized variable values with some predetermined values that will not converge:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict() ['linear.weight'].data[0]=torch.tensor([[-5]])\n",
    "model.state_dict() ['linear.bias'].data[0]=torch.tensor([[-10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a <code> plot_error_surfaces</code> object to visualize the data space and the parameter space during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_surface=plot_error_surfaces(15,13,data_set[:][0],data_set[:][1],30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost or criterion function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_rms=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataloader object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=2\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ref2\"></a>\n",
    "<h2 align=center>Train the Model via Batch Gradient Descent </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    \n",
    "    for x,y in trainloader:\n",
    "        #make a prediction \n",
    "        yhat= model(x)\n",
    "        #calculate the loss\n",
    "        loss = criterion_rms(yhat, y)\n",
    "        #clear gradient\n",
    "        optimizer.zero_grad()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "        #for plotting\n",
    "        get_surface.get_stuff(model,loss.tolist())\n",
    "        #plot every 20 iterataions\n",
    "    if epoch%20==0:\n",
    "        get_surface.plot_ps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual class of each sample and calculate the accuracy on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat=model(data_set.x)\n",
    "lable=yhat>0.5\n",
    "print(torch.mean((lable==data_set.y.type(torch.ByteTensor)).type(torch.float)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Accuracy is 60% compared to 100% in the last lab using a good Initialization value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the Authors:  \n",
    "\n",
    " [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering. His research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: [Michelle Carey](  https://www.linkedin.com/in/michelleccarey/), [Mavis Zhou](  https://www.linkedin.com/in/jiahui-mavis-zhou-a4537814a/) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 [cognitiveclass.ai](cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
